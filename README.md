
### Course Information

* **Course Info:**	CS7545, Fall 2018
* **Instructor:**	Jacob Abernethy
    - **Office:** Klaus 2134
    - **Email:** prof_at_gatech_dot_edu
    - **Office Hours:** 10-11am Wednesdays in Klaus 2134
* **Course Time&Place:**	MW 4:30-5:45pm, Klaus 2443
* **Teaching Assistants**:
    - *Bhuvesh Kumar*
        - **Email:** bhuvesh_at_gatech.edu
        - **Office Hours**: Mondays 2:30-3:30pm, alcove of Klaus 2116/2124
    - *Jun-Kun Wang*
        - **Email:** jimwang_at_gatech.edu
        - **Office Hours**: Wednesdays 11am-12pm, alcove of Klaus 2116/2124


### Course Description

This course will study theoretical aspects of prediction and decision-making probelms, where our goal is to understand themathematical underpinnings of machine learning. A primary objective of the class is to bring students to the frontiers of research and to prepare students to publish in this area. The course will cover, among other things, concentration inqualities, uniform deviation bounds, Vapnik-Chervonenkis Theory, Rademacher Complexity, margin bounds, boosting, some theoretical aspects of deep learning, online learning theory, regret minimization, multi-armed bandit algorithms, and connections to convex optimization. Along the way, we may dive into several related topics, including minimax equilibrium in games, calibration, sequential portfolio selection, option pricing, and differential privacy.

**Prerequisites:** Familiarity with the analysis of algorithms, probabilistic analysis, and several similar topics. CS7641 (Machine Learning) will be quite helpful but not strictly necessary. The material is going to be about 90% "theory" and thus potential students must have a strong mathematical background. We shall rely heavily on techniques from calculus, probability, and convex analysis, but many tools will be presented in lecture.

**Coursework:** There will be 5 problem sets throughout the semester.

**Grade Breakdown:**
* 50% - *Homeworks*
* 40% - *Final Exam*
* 10% - *Participation*

**Note**: The final exam will be held on Friday, December 7, from 2:40-5:30pm.


### References:

Roughly half of the course will follow material from the following text:

 * "[Foundations of Machine Learning](https://www.amazon.com/Foundations-Machine-Learning-Adaptive-Computation/dp/026201825X)" by Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar

Much of the material in online learning (aka regret minimization) is of my own taste, and I will present these topics how I enjoy. But for students that want reading material on this topic, there are several surveys releaseSd in the last several years that explore several many that we shall cover. I will link to them here, and will mention them in various lectures when appropriate:

* [The Multiplicative Weights Update Method](http://www.cs.princeton.edu/~arora/pubs/MWsurvey.pdf) by Sanjeev Arora, Elad Hazan, and Satyen Kale.
* [Online Learning and Online Convex Optimization survey](http://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf) by Shai Shalev-Shwartz.
* [The convex optimization approach to regret minimization survey](http://www.cs.princeton.edu/~ehazan/papers/OCO-survey.pdf) by Elad Hazan.
* [Sasha Rakhlin's Lecture Notes](http://www-stat.wharton.upenn.edu/~rakhlin/courses/stat928/stat928_notes.pdf).


### Scribe Notes

| Lecture | Date  | Topic |
| :------------: |:-------------: |:-------------: |
| [1](./scribe/lec1.pdf)   | 20 Aug 2018 | Introduction and norms |
| [2](./scribe/lec2.pdf)    | 22 Aug 2018 | Convex analysis |
| [3](./scribe/lec3.pdf)    | 27 Aug 2018 | Convex Analysis + Deviation Bounds |

[The Latex template for scribes is available here.](./scribe/CS7545scribe_template.tex)

### Homeworks

| Homework | Due Date  | 
| :------------: |:-------------: |
| [1](./hw/hw1.pdf) | Sep 10 2018, 2:00 pm |
| [1](./hw/hw2.pdf) | Sep 24 2018, 2:00 pm |

[The Latex template for HW submissions is available here.](./hw/CS7545hw_template.tex)

